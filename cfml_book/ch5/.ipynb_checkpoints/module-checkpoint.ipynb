{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e840d9f3-4f47-448b-8376-779700f5af34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "import numpy as np\n",
    "from sklearn.utils import check_random_state\n",
    "\n",
    "from utils import sample_action_fast, sigmoid, logging_policy\n",
    "\n",
    "\n",
    "def generate_synthetic_data(\n",
    "    num_data: int,\n",
    "    theta_g: np.ndarray,\n",
    "    M_g: np.ndarray,\n",
    "    b_g: np.ndarray,\n",
    "    theta_h: np.ndarray,\n",
    "    M_h: np.ndarray,\n",
    "    b_h: np.ndarray,\n",
    "    phi_a: np.ndarray,\n",
    "    lambda_: float = 0.5,\n",
    "    dim_context: int = 5,\n",
    "    num_actions: int = 50,\n",
    "    num_clusters: int = 3,\n",
    "    beta: float = 1.0,\n",
    "    lam: float = 0.5,\n",
    "    sigma: float = 1.0,\n",
    "    random_state: int = 12345,\n",
    ") -> dict:\n",
    "    \"\"\"オフ方策学習におけるログデータを生成する.\"\"\"\n",
    "    random_ = check_random_state(random_state)\n",
    "    x = random_.normal(size=(num_data, dim_context))\n",
    "    one_hot_a, one_hot_c = np.eye(num_actions), np.eye(num_clusters)\n",
    "\n",
    "    # 期待報酬関数を定義する\n",
    "    g_x_c = sigmoid(\n",
    "        (x - x ** 2) @ theta_g + (x ** 3 + x ** 2 - x) @ M_g @ one_hot_c + b_g\n",
    "    )\n",
    "    h_x_a = sigmoid(\n",
    "        (x ** 3 + x ** 2 - x) @ theta_h + (x - x ** 2) @ M_h @ one_hot_a + b_h\n",
    "    )\n",
    "    q_x_a = (1 - lambda_) * g_x_c[:, phi_a] + lambda_ * h_x_a\n",
    "\n",
    "    # データ収集方策を定義する\n",
    "    pi_0 = logging_policy(q_x_a, beta=beta, sigma=sigma, lam=lam)\n",
    "    idx = np.arange(num_data)\n",
    "    pi_0_c = np.zeros((num_data, num_clusters))\n",
    "    for c_ in range(num_clusters):\n",
    "        pi_0_c[:, c_] = pi_0[:, phi_a == c_].sum(1)\n",
    "\n",
    "    # 行動や報酬を抽出する\n",
    "    a = sample_action_fast(pi_0, random_state=random_state)\n",
    "    q_x_a_factual = q_x_a[idx, a]\n",
    "    r = random_.binomial(n=1, p=q_x_a_factual)\n",
    "\n",
    "    return dict(\n",
    "        num_data=num_data,\n",
    "        num_actions=num_actions,\n",
    "        num_clusters=num_clusters,\n",
    "        x=x,\n",
    "        a=a,\n",
    "        c=phi_a[a],\n",
    "        r=r,\n",
    "        phi_a=phi_a,\n",
    "        pi_0=pi_0,\n",
    "        pi_0_c=pi_0_c,\n",
    "        pscore=pi_0[idx, a],\n",
    "        pscore_c=pi_0_c[idx, phi_a[a]],\n",
    "        g_x_c=(1 - lambda_) * g_x_c,\n",
    "        h_x_a=lambda_ * h_x_a,\n",
    "        q_x_a=q_x_a,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7417bcc3-2aef-4091-a2c1-10ddcecf6905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.utils import check_random_state\n",
    "import torch\n",
    "\n",
    "\n",
    "def sample_action_fast(pi: np.ndarray, random_state: int = 12345) -> np.ndarray:\n",
    "    \"\"\"与えられた方策に従い、行動を高速に抽出する.\"\"\"\n",
    "    random_ = check_random_state(random_state)\n",
    "    uniform_rvs = random_.uniform(size=pi.shape[0])[:, np.newaxis]\n",
    "    cum_pi = pi.cumsum(axis=1)\n",
    "    flg = cum_pi > uniform_rvs\n",
    "    sampled_actions = flg.argmax(axis=1)\n",
    "    return sampled_actions\n",
    "\n",
    "\n",
    "def sigmoid(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"シグモイド関数.\"\"\"\n",
    "    return np.exp(np.minimum(x, 0)) / (1.0 + np.exp(-np.abs(x)))\n",
    "\n",
    "\n",
    "def softmax(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"ソフトマックス関数.\"\"\"\n",
    "    b = np.max(x, axis=1)[:, np.newaxis]\n",
    "    numerator = np.exp(x - b)\n",
    "    denominator = np.sum(numerator, axis=1)[:, np.newaxis]\n",
    "    return numerator / denominator\n",
    "\n",
    "\n",
    "def logging_policy(\n",
    "    q_func: np.ndarray,\n",
    "    beta: float = 1.0,\n",
    "    sigma: float = 1.0,\n",
    "    lam: float = 0.5,\n",
    "    random_state: int = 12345,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"ソフトマックス関数により方策を定義する.\"\"\"\n",
    "    random_ = check_random_state(random_state)\n",
    "    noise = random_.normal(scale=sigma, size=q_func.shape)\n",
    "    pi = softmax(beta * (lam * q_func + (1.0 - lam) * noise))\n",
    "\n",
    "    return pi / pi.sum(1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class RegBasedPolicyDataset(torch.utils.data.Dataset):\n",
    "    context: np.ndarray\n",
    "    action: np.ndarray\n",
    "    reward: np.ndarray\n",
    "\n",
    "    def __post_init__(self):\n",
    "        \"\"\"initialize class\"\"\"\n",
    "        assert self.context.shape[0] == self.action.shape[0] == self.reward.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (\n",
    "            self.context[index],\n",
    "            self.action[index],\n",
    "            self.reward[index],\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.context.shape[0]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class GradientBasedPolicyDataset(torch.utils.data.Dataset):\n",
    "    context: np.ndarray\n",
    "    action: np.ndarray\n",
    "    reward: np.ndarray\n",
    "    pscore: np.ndarray\n",
    "    q_hat: np.ndarray\n",
    "    pi_0: np.ndarray\n",
    "\n",
    "    def __post_init__(self):\n",
    "        \"\"\"initialize class\"\"\"\n",
    "        assert (\n",
    "            self.context.shape[0]\n",
    "            == self.action.shape[0]\n",
    "            == self.reward.shape[0]\n",
    "            == self.pscore.shape[0]\n",
    "            == self.q_hat.shape[0]\n",
    "            == self.pi_0.shape[0]\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (\n",
    "            self.context[index],\n",
    "            self.action[index],\n",
    "            self.reward[index],\n",
    "            self.pscore[index],\n",
    "            self.q_hat[index],\n",
    "            self.pi_0[index],\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.context.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c55bfe-7e61-4e19-941d-bdb63823ac4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
